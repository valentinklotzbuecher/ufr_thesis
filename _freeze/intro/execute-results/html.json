{
  "hash": "a7c0caf931d7680b3865192dffa37ceb",
  "result": {
    "engine": "knitr",
    "markdown": "# Introduction\n\nThis is a book created from markdown and executable code.\n\nSee @knuth84 for additional discussion of literate programming.\n\nWhat follows is generated with GPT4o as blindtext to illustrate formatting options.\n\n# The Importance of Modern Tools in Economic Research\n\nEmbarking on a thesis in economics is an intellectually stimulating yet demanding journey, one that requires not just analytical rigor but also clear communication and effective organization of complex ideas. As you delve into this process, the tools you choose can greatly influence both your efficiency and the quality of your work. This is where Quarto and literate programming come into play, offering a robust framework that integrates writing, coding, and data visualization into a cohesive whole. By adopting these tools, you are not only streamlining your workflow but also ensuring that your research is transparent, reproducible, and professionally presented.\n\nIn the realm of economic research, clarity is paramount. Your thesis must convey intricate methodologies and detailed results in a manner that is accessible and understandable, not just to your thesis committee but to the broader academic community. Quarto allows you to write your thesis in a format that interweaves narrative and analysis, making it easier for your readers to follow the logical flow of your argument. The integration of literate programming takes this a step further by embedding your code within the document itself. This approach ensures that every piece of analysis is directly linked to the code that generated it, providing a level of transparency that is essential for the credibility of your work. Readers can see exactly how you arrived at your conclusions, which not only enhances the trustworthiness of your findings but also facilitates the replication of your results by other researchers.\n\nReproducibility is a cornerstone of good research, particularly in economics, where the ability to replicate findings is critical to the validation of results. With Quarto, you can create dynamic documents that automatically update analyses and results whenever data or parameters are changed. This means that as your research evolves, your thesis remains current without the need for extensive manual updates. This feature is particularly useful in the context of collaborative research or when working with large datasets, where maintaining consistency and accuracy across multiple revisions can be challenging. By using literate programming within Quarto, you are not just writing a static document; you are creating a living, breathing piece of research that evolves with your work.\n\nEfficiency is another significant benefit of using Quarto and literate programming. The process of writing a thesis is inherently time-consuming, and any tool that can reduce the time spent on formatting, revising, or switching between different software platforms is invaluable. Quarto brings together writing, coding, and data visualization in a single environment, allowing you to focus on the intellectual aspects of your research rather than the mechanics of document preparation. This integrated approach minimizes the risk of errors and inconsistencies that can arise from using multiple tools, and it accelerates the overall workflow, giving you more time to refine your analysis and polish your arguments.\n\nThe presentation of your results is equally important, particularly in a field like economics, where the clarity and professionalism of your graphs, tables, and equations can significantly impact how your work is received. Quarto supports advanced typesetting features, enabling you to produce documents that are not only clear and well-organized but also aesthetically pleasing. Whether you are presenting complex econometric models, detailed statistical tables, or intricate graphs, Quarto ensures that your work looks professional and meets the high standards expected in academic publications.\n\nFurthermore, by adopting Quarto and literate programming, you are equipping yourself with modern skills that extend beyond the completion of your thesis. In todayâ€™s data-driven world, the ability to produce reproducible research and to document the research process in a clear and transparent way is highly valued, both in academia and in the private sector. Mastering these tools gives you a competitive edge, whether you are pursuing further academic research, entering the job market, or working in a professional setting where data analysis and communication are key components of the role.\n\nIn conclusion, the use of Quarto and literate programming in your economics thesis is more than just a choice of tools; it represents a commitment to producing high-quality, transparent, and reproducible research. By integrating your writing, coding, and data analysis into a single, dynamic document, you are not only enhancing the quality of your thesis but also streamlining the process and developing skills that will serve you well in your future career. Embracing these modern approaches to research documentation will not only make your thesis journey smoother and more efficient but also ensure that your work stands out in the academic community for its clarity, rigor, and professionalism.\n\n# Probit Estimation in Economics\n\nIn many economic research contexts, we are interested in modeling binary outcome variables, such as whether an individual chooses to participate in the labor force or whether a firm decides to enter a particular market. Probit models are commonly used for this purpose, as they allow us to estimate the probability that a particular outcome occurs given a set of explanatory variables.\n\n## The Probit Model\n\nThe Probit model assumes that there is an underlying latent variable $Y^*$ that is a linear function of the explanatory variables $X$ and a normally distributed error term $\\epsilon$:\n\n$$\nY^* = X\\beta + \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, 1)\n$$\n\nHowever, we do not observe $Y^* $ directly. Instead, we observe a binary outcome $Y$ defined as:\n\n$$\nY = \n\\begin{cases} \n1 & \\text{if } Y^* > 0 \\\\\n0 & \\text{if } Y^* \\leq 0\n\\end{cases}\n$$\n\nThe probability that $Y = 1 $ (i.e., the event of interest occurs) is given by:\n\n$$\nP(Y = 1 \\mid X) = \\Phi(X\\beta)\n$$\n\nwhere $\\Phi(\\cdot)$ is the cumulative distribution function (CDF) of the standard normal distribution.\n\n## Estimating the Model\n\nIn practice, we estimate the vector of coefficients $\\beta $ using maximum likelihood estimation (MLE). The likelihood function for a sample of observations $i = 1, \\dots, n $ is given by:\n\n$$\nL(\\beta) = \\prod_{i=1}^n \\Phi(X_i\\beta)^{Y_i} \\left[1 - \\Phi(X_i\\beta)\\right]^{1-Y_i}\n$$\n\nThe log-likelihood, which is typically maximized numerically to find the MLE of $\\beta $, is:\n\n$$\n\\log L(\\beta) = \\sum_{i=1}^n \\left[ Y_i \\log \\Phi(X_i\\beta) + (1 - Y_i) \\log \\left(1 - \\Phi(X_i\\beta)\\right) \\right]\n$$\n\n### Code Example: Estimating a Probit Model\n\nIn practice, you might use a statistical software package to estimate a Probit model. For example, in R, you could use the following code:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load necessary libraries\nlibrary(tidyverse)  # For data manipulation and visualization\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n-- Attaching core tidyverse packages ------------------------ tidyverse 2.0.0 --\nv dplyr     1.1.4     v readr     2.1.5\nv forcats   1.0.0     v stringr   1.5.1\nv ggplot2   3.5.1     v tibble    3.2.1\nv lubridate 1.9.3     v tidyr     1.3.1\nv purrr     1.0.2     \n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(margins)    # For calculating marginal effects\nlibrary(modelsummary)    \n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`modelsummary` 2.0.0 now uses `tinytable` as its default table-drawing\n  backend. Learn more at: https://vincentarelbundock.github.io/tinytable/\n\nRevert to `kableExtra` for one session:\n\n  options(modelsummary_factory_default = 'kableExtra')\n  options(modelsummary_factory_latex = 'kableExtra')\n  options(modelsummary_factory_html = 'kableExtra')\n\nSilence this message forever:\n\n  config_modelsummary(startup_message = FALSE)\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(flextable)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttache Paket: 'flextable'\n\nDas folgende Objekt ist maskiert 'package:purrr':\n\n    compose\n```\n\n\n:::\n\n```{.r .cell-code}\n# Load the built-in dataset\ndata(\"mtcars\")\n\n# Inspect the data\nglimpse(mtcars)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 32\nColumns: 11\n$ mpg  <dbl> 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8,~\n$ cyl  <dbl> 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 8,~\n$ disp <dbl> 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 140.8, 16~\n$ hp   <dbl> 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, 180~\n$ drat <dbl> 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92,~\n$ wt   <dbl> 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3.~\n$ qsec <dbl> 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 22.90, 18~\n$ vs   <dbl> 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,~\n$ am   <dbl> 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,~\n$ gear <dbl> 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3,~\n$ carb <dbl> 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1, 1, 2,~\n```\n\n\n:::\n\n```{.r .cell-code}\n# Create a binary outcome variable: 1 if mpg > 20, 0 otherwise\nmtcars <- mtcars %>%\n  mutate(high_mpg = ifelse(mpg > 20, 1, 0))\n\n# Fit the Probit model\nmodel <- glm(high_mpg ~ hp + wt + cyl,\n             family = binomial(link = \"probit\"),\n             data = mtcars)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: glm.fit: Algorithmus konvergierte nicht\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: glm.fit: Angepasste Wahrscheinlichkeiten mit numerischem Wert 0 oder 1\naufgetreten\n```\n\n\n:::\n\n```{.r .cell-code}\n# Summarize the model results\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = high_mpg ~ hp + wt + cyl, family = binomial(link = \"probit\"), \n    data = mtcars)\n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)\n(Intercept)   227.9647 59356.0515   0.004    0.997\nhp             -0.5989   173.1890  -0.003    0.997\nwt            -60.3149 16456.6441  -0.004    0.997\ncyl             6.2871  4190.6791   0.002    0.999\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 4.386e+01  on 31  degrees of freedom\nResidual deviance: 8.744e-09  on 28  degrees of freedom\nAIC: 8\n\nNumber of Fisher Scoring iterations: 25\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate marginal effects\nmargins_model <- margins(model)\n\n# Summarize the marginal effects\n#msummary(margins_model)\n\n# Visualize marginal effects\nplot(margins_model)\n\n# Interpretation:\n# The summary(model) output provides the estimated coefficients for the Probit model.\n# The coefficients indicate the direction of the effect, but the marginal effects\n# calculated via the margins() function tell us how a unit change in each predictor\n# affects the probability of a car having high MPG.\n```\n\n::: {.cell-output-display}\n![Marginal effects](intro_files/figure-html/fig-marginsplot-1.png){#fig-marginsplot width=672}\n:::\n:::\n\n\n\n@fig-marginsplot shows the marginal effects.\n\n\n\n::: {#tbl-marginsplot .cell tbl-cap='Marginal effects'}\n\n```{.r .cell-code}\nsummarytable = msummary(list(margins_model),\n         output = \"flextable\",\n         fmt = fmt_statistic(estimate = 3,\n                             std.error = 3,\n                             conf.low = 3,\n                             conf.high = 3,\n                             nobs = 0),\n         stars = c('*' = 0.1, '**' = 0.05, '***' = 0.01),\n         estimate = \"{estimate}{stars}\",\n         statistic = \"({std.error})\",\n         conf_level = .95, \n         align=\"lc\",\n         gof_omit = 'AIC|BIC|R2 Adj.|RMSE|Std.Errors|R2 Within Adj.|R2 Within|R2',\n         coef_rename = c(\"lag_aid_gdp\" = \"Aid/GDP, t-1\"\n                           )\n         )\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}